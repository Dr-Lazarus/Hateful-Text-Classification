{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Task 1: Logistic Regression\n",
    "\n",
    "### Key Task Deliverables\n",
    "1. Code implementation of the Logistic Regression model.\n",
    "2. Prediction made by your Logistic Regression on the Test set. Note that you are welcome to submit your predicted labels to Kaggle but you will need to submit the final prediction output in the final project submission. Please label the file as \"LogRed_Prediction.csv\".\n",
    "\n",
    "### Notations\n",
    "\n",
    "- `n` : number of features\n",
    "- `m` : number of training examples\n",
    "- `X` : input data matrix of shape (`m` X `n`)\n",
    "- `y` : true/target value (0 or 1)\n",
    "- `x(i), y(i)` : ith training example\n",
    "- `w` : weights (parameters) of shape (`n` x 1)\n",
    "- `b` : bias (parameter), a real number that can be broadcasted\n",
    "- `y_hat`: Hypothesis (output values between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    " \n",
    "def sigmoid(z):\n",
    "  return 1.0/(1 + np.exp(-z))\n",
    "\n",
    "def loss(y, y_hat):\n",
    "  loss = -np.mean(y*(np.log(y_hat)) - (1-y)*np.log(1-y_hat))\n",
    "  return loss\n",
    "\n",
    "def gradients(X, y, y_hat):\n",
    "  # X --> Input.\n",
    "  # y --> true/target value.\n",
    "  # y_hat --> hypothesis/predictions.\n",
    "  # w --> weights (parameter).\n",
    "  # b --> bias (parameter).\n",
    "  \n",
    "  # m-> number of training examples.\n",
    "  m = X.shape[0]\n",
    "  \n",
    "  # Gradient of loss w.r.t weights.\n",
    "  dw = (1/m)*np.dot(X.T, (y_hat - y))\n",
    "  \n",
    "  # Gradient of loss w.r.t bias.\n",
    "  db = (1/m)*np.sum((y_hat - y)) \n",
    "  \n",
    "  return dw, db\n",
    "\n",
    "def plot_decision_boundary(X, w, b):\n",
    "    \n",
    "    # X --> Inputs\n",
    "    # w --> weights\n",
    "    # b --> bias\n",
    "    \n",
    "    # The Line is y=mx+c\n",
    "    # So, Equate mx+c = w.X + b\n",
    "    # Solving we find m and c\n",
    "    x1 = [min(X[:,0]), max(X[:,0])]\n",
    "    m = -w[0]/w[1]\n",
    "    c = -b/w[1]\n",
    "    x2 = m*x1 + c\n",
    "    \n",
    "    # Plotting\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"g^\")\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\")\n",
    "    plt.xlim([-2, 2])\n",
    "    plt.ylim([0, 2.2])\n",
    "    plt.xlabel(\"feature 1\")\n",
    "    plt.ylabel(\"feature 2\")\n",
    "    plt.title('Decision Boundary')\n",
    "    plt.plot(x1, x2, 'y-')\n",
    "\n",
    "def normalize(X):\n",
    "    \n",
    "    # X --> Input.\n",
    "    \n",
    "    # m-> number of training examples\n",
    "    # n-> number of features \n",
    "    m, n = X.shape\n",
    "    \n",
    "    # Normalizing all the n features of X.\n",
    "    for i in range(n):\n",
    "        X = (X - X.mean(axis=0))/X.std(axis=0)\n",
    "        \n",
    "    return X\n",
    "\n",
    "def train(X, y, bs, epochs, lr):\n",
    "  # X --> Input.\n",
    "  # y --> true/target value.\n",
    "  # bs --> Batch Size.\n",
    "  # epochs --> Number of iterations.\n",
    "  # lr --> Learning rate.\n",
    "      \n",
    "  # m-> number of training examples\n",
    "  # n-> number of features \n",
    "  m, n = X.shape\n",
    "  \n",
    "  # Initializing weights and bias to zeros.\n",
    "  w = np.zeros((n,1))\n",
    "  b = 0\n",
    "  \n",
    "  # Reshaping y.\n",
    "  y = y.reshape(m,1)\n",
    "  \n",
    "  # Normalizing the inputs.\n",
    "  # x = normalize(X)\n",
    "  \n",
    "  # Empty list to store losses.\n",
    "  losses = []\n",
    "  \n",
    "  # Training loop.\n",
    "  for epoch in range(epochs):\n",
    "      for i in range((m-1)//bs + 1):\n",
    "          \n",
    "          # Defining batches. SGD.\n",
    "          start_i = i*bs\n",
    "          end_i = start_i + bs\n",
    "          xb = X[start_i:end_i]\n",
    "          yb = y[start_i:end_i]\n",
    "          \n",
    "          # Calculating hypothesis/prediction.\n",
    "          y_hat = sigmoid(np.dot(xb, w) + b)\n",
    "          \n",
    "          # Getting the gradients of loss w.r.t parameters.\n",
    "          dw, db = gradients(xb, yb, y_hat)\n",
    "          \n",
    "          # Updating the parameters.\n",
    "          w -= lr*dw\n",
    "          b -= lr*db\n",
    "      \n",
    "      # Calculating loss and appending it in the list.\n",
    "      l = loss(y, sigmoid(np.dot(X, w) + b))\n",
    "      # print(l)\n",
    "      losses.append(l)\n",
    "      \n",
    "  # returning weights, bias and losses(List).\n",
    "  return w, b, losses\n",
    "\n",
    "def predict(X):\n",
    "  # X --> Input.\n",
    "  # Normalizing the inputs.\n",
    "  # x = normalize(X)\n",
    "  \n",
    "  # Calculating presictions/y_hat.\n",
    "  preds = sigmoid(np.dot(X, w) + b)\n",
    "  \n",
    "  # Empty List to store predictions.\n",
    "  pred_class = []\n",
    "  # if y_hat >= 0.5 --> round up to 1\n",
    "  # if y_hat < 0.5 --> round up to 1\n",
    "  pred_class = [1 if i > 0.5 else 0 for i in preds]\n",
    "  \n",
    "  return np.array(pred_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_tfidf_features.csv\")\n",
    "test_df = pd.read_csv(\"test_tfidf_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38122672253258844\n"
     ]
    }
   ],
   "source": [
    "test_df.head(5)\n",
    "# Number of ratio of 1s to 0s in label (class balance)\n",
    "print(sum(train_df[\"label\"])/len(train_df[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = train_df.drop(['id','label'], axis = 1).values\n",
    "y = train_df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for scikitlearn's logistic regression: \n",
      "0.6752934368606008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# sk-learn's implementation\n",
    "\n",
    "reg = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred_SK = reg.predict(X_test)\n",
    "f1_SK = f1_score(y_test, y_pred_SK, average='macro')\n",
    "print(\"F1 Score for scikitlearn's logistic regression: \")\n",
    "print(f1_SK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for our logistic regression: \n",
      "0.6822884427261123\n"
     ]
    }
   ],
   "source": [
    "w, b, l = train(X_train, y_train, bs=100, epochs=1000, lr=0.1)\n",
    "y_pred = predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1 Score for our logistic regression: \")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting...\n",
      "concatenating...\n",
      "saving...\n"
     ]
    }
   ],
   "source": [
    "idColDf = test_df[\"id\"]\n",
    "X_submit_test = test_df.drop(['id'], axis = 1).values\n",
    "\n",
    "# Submission using OUR logistic regression weights\n",
    "print(\"training...\")\n",
    "w, b, l = train(X, y, bs=100, epochs=1000, lr=0.1)\n",
    "print(\"predicting...\")\n",
    "y_submit_pred = predict(X_submit_test)\n",
    "y_submit_pred_df = pd.DataFrame(y_submit_pred)\n",
    "print(\"concatenating...\")\n",
    "submission = pd.concat([idColDf,y_submit_pred_df],axis=1)\n",
    "print(\"saving...\")\n",
    "submission.to_csv('LogRed_Prediction.csv', index=False)\n",
    "\n",
    "# Takes approximately 25+ minutes to run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Task 2: PCA\n",
    "\n",
    "### Key Task Deliverables\n",
    "1. Code implementation of PCA on the train and test sets. Note that you are allowed to use the sklearn package for this task.\n",
    "2. Report the Macro F1 scores for applying 2000, 1000, 500, and 100 components on the test set. Note that you will have to submit your predicted labels to Kaggle to retrieve the Macro F1 scores for the test set and report the results in your final report. Use KNN as the machine learning model for your training and prediction (You are also allowed to use the sklearn package for KNN implementation) (set n_neighbors=2).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for 2000 Components: 0.48337877074774893\n",
      "F1 Score for 1000 Components: 0.5665376732277406\n",
      "F1 Score for 500 Components: 0.5415714030120706\n",
      "F1 Score for 100 Components: 0.5489194994537527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "for num in [2000,1000,500,100] :\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "  neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "  pca = PCA(n_components=num)\n",
    "  pca.fit(X_train)\n",
    "  \n",
    "  X_train = pca.transform(X_train)\n",
    "  X_test = pca.transform(X_test)\n",
    "  \n",
    "  neigh.fit(X_train, y_train)\n",
    "  y_pred = neigh.predict(X_test)\n",
    "  f1 = f1_score(y_test, y_pred, average='macro')\n",
    "  print(f\"F1 Score for {num} Components: {f1}\")\n",
    "\n",
    "# Report the Macro F1 scores for applying 2000, 1000, 500, and 100 components on the test set\n",
    "# Use KNN as the machine learning model for your training and prediction (You are also allowed to use the sklearn package for KNN implementation) (set n_neighbors=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "- F1 Score for 2000 Components: 0.48337877074774893\n",
    "- F1 Score for 1000 Components: 0.5665376732277406\n",
    "- F1 Score for 500 Components: 0.5415714030120706\n",
    "- F1 Score for 100 Components: 0.5489194994537527\n",
    "\n",
    "### Analysis:\n",
    "- F1_score is lowest at 2000 Components, and highest at 1000 Components.\n",
    "- For our train-test split, the number of components did not appear to have a strong correlation with the F1_score.\n",
    "- Higher scores for lower components could be due to the removal of substantial noise, even though we might expect the opposite to be true due to the the decrease in explained variance for low components.\n",
    "- This may be because the dataset has a high amount of noise that can be removed to yield more predictive features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Task 3: Machine Learning Model for Hate Text Classification\n",
    "\n",
    "### Key Task Deliverables\n",
    "\n",
    "1. Code implementation of all the models that you have tried. Please include comments on your implementation (i.e., tell us the models you have used and list the key hyperparameter settings.\n",
    "\n",
    "2. Submit your predicted labels for the test set to Kaggle. You will be able to see your model performance on the public leaderboard. Please make your submission under your registered team name! We will award the points according to the ranking of the registered team name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### üí° Multinomial NB   \n",
    "\n",
    "\n",
    " ##### üëâ    What is the model ? \n",
    "\n",
    "  * **Multinomial NB** implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes.\n",
    "\n",
    "           \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    " ##### üëâ    Why we chose to test this model ? \n",
    "  \n",
    " * The reason behind testing this model is based on the research paper released regarding the classification of hate speech 'A comparison of classification algorithms for hate speech detection'. The results show that the Multinomial Naive Bayes algorithm produces the best model with the highest recall value of **93.2%** which has an accuracy value of **71.2%** for the classification of hate speech. (**Putri et al., 2020**).\n",
    "\n",
    "### üí° Hyperparameters of the model \n",
    "* **alpha:** float, default = 1.0\n",
    "<br> Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).\n",
    "\n",
    "* **fit_prior:** bool, default = True\n",
    "<br> Whether to learn class prior probabilities or not. If false, a uniform prior will be used.\n",
    "\n",
    "* **class_prior:** array-like of shape (n_classes,), default = None <br> Prior probabilities of the classes. If specified, the priors are not adjusted according to the data\n",
    "\n",
    "### üí° Hyperparameters tuning \n",
    "\n",
    "   *  We are utilizing the **Optuna** hyperparameter optimization framework to tune our hyperparameters.\n",
    "\n",
    "   \n",
    " ##### üëâ    Why we chose this framework ?\n",
    "\n",
    "  *  Optuna boasts the following features: \n",
    "      - **Lightweight, versatile, and platform agnostic architecture**\n",
    "           - Handle a wide variety of tasks with a simple installation that has few requirements.\n",
    "       - **Pythonic search spaces**\n",
    "            - Define search spaces using familiar Python syntax including conditionals and loops.\n",
    "       - **Efficient optimization algorithms**\n",
    "            - Adopt state-of-the-art algorithms for sampling hyperparameters and efficiently pruning unpromising trials.\n",
    "       - **Easy parallelization**\n",
    "            - Scale studies to tens or hundreds or workers with little or no changes to the code.\n",
    "       - **Quick visualization**\n",
    "            - Inspect optimization histories from a variety of plotting functions.\n",
    "     \n",
    "     Optuna also allowed us to find the optimal parameters at a faster rate as opposed to grid search though there is a trade off in accuracy. \n",
    "\n",
    "\n",
    "\n",
    "### üí° Results \n",
    "\n",
    "##### üëâ    F1 score of Model on public dataset (20%) \n",
    "\n",
    "* **0.7100**\n",
    " \n",
    "\n",
    "Kaggle Notebook Link: https://www.kaggle.com/visshalnatarajan/multinomial-nb-with-optuna-920b9f62\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Model Implementation\n",
    "\n",
    "# Imports\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"bmh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "print(\"reading CSVs\")\n",
    "train_df = pd.read_csv(\"train_tfidf_features.csv\")\n",
    "test_df = pd.read_csv(\"test_tfidf_features.csv\")\n",
    "\n",
    "print(\"creating X and y\")\n",
    "X = train_df.drop(['id','label'], axis = 1).values\n",
    "y = train_df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=3,n_repeats=3,random_state=1)\n",
    "    \n",
    "    ### define params grid to search maximum accuracy\n",
    "    alpha = trial.suggest_float('alpha',2.0,5.0)\n",
    "    fit_prior =  trial.suggest_categorical('fit_prior', [True, False])\n",
    "\n",
    "    ### modeling with suggested params\n",
    "    model = MultinomialNB(alpha = alpha,fit_prior = fit_prior)\n",
    "\n",
    "    ## cross validation score\n",
    "    score = cross_val_score(model, X, y, n_jobs=2, cv=cv, scoring=\"f1_macro\")\n",
    "    f1_mean = score.mean()\n",
    "    return f1_mean\n",
    "    \n",
    "study = optuna.create_study(direction='maximize') # maximize accuracy\n",
    "study.optimize(objective, n_trials=None, timeout=42000, n_jobs = 2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FILE_NAME= '/kaggle/working/Winner.csv'\n",
    "model =  MultinomialNB(alpha =study.best_trial.params['alpha'],fit_prior = study.best_trial.params['fit_prior'],)\n",
    "model.fit(X,y)\n",
    "idColDf = test_df[\"id\"]\n",
    "X_submit_test = test_df.drop(['id'], axis = 1).values\n",
    "\n",
    "# Submission using OUR logistic regression weights\n",
    "y_submit_pred = model.predict(X_submit_test)\n",
    "y_submit_pred_df = pd.DataFrame(y_submit_pred)\n",
    "submission = pd.concat([idColDf,y_submit_pred_df],axis=1)\n",
    "submission.columns = ['id','label']\n",
    "submission.to_csv(FILE_NAME, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "### üí° XGBoost\n",
    "\n",
    "\n",
    " ##### üëâ    What is the model ?\n",
    "\n",
    "  * **XGBoost** is a tree-based ensemble model which stands for ‚Äúgradient-boosted decision tree (GBDT)‚Äù. Compared to the random forest, XGBoost implement the idea of ‚Äúboosting‚Äù which establishes a connection between trees. Therefore, trees in XGBoost models are no longer independent of each other and the model eventually becomes an orderly collective decision-making system.\n",
    "\n",
    "\n",
    " ##### üëâ    Why we chose to test this model ?\n",
    " * XGBoost is an ensemble algorithm that has higher predicting power and performance, and it is achieved by improvisation on Gradient Boosting framework by introducing some accurate approximation algorithms. We speculate that by **gradient boost mechanism** and **self-regularization** embedded in the model can potentially increase the accuracy of predictions and reduce the risk of overfitting for tree-based models.\n",
    "\n",
    "\n",
    "### üí° Hyperparameters of the model\n",
    "* **eta:** float, default = 0.3\n",
    "<br> The step size in fitting.\n",
    "\n",
    "* **objective:** default = reg:squarederror\n",
    "<br> Specify the learning task.\n",
    "\n",
    "* **num_round:** integer\n",
    "<br> Same as ‚Äún_estimators‚Äù, the number for boosting, which also decides the number of trees in the ensemble forest.\n",
    "\n",
    "* **subsample:** float, default = 1\n",
    "<br> Subsample ratio of the training instances (prevent overfitting).\n",
    "\n",
    "* **min_child_weight:** float, default = 1\n",
    "<br> Minimum sum of instance weight needed in a child. The larger, the more conservative the model will be.\n",
    "\n",
    "* **max_depth:** integer, default = 6\n",
    "<br> Maximum depth of a tree.\n",
    "\n",
    "* **gamma:** float, default = 0\n",
    "<br> Minimum loss reduction required to make a further partition on a leaf node.\n",
    "\n",
    "* **colsample_bytree:** default = 1\n",
    "<br> The subsample ratio of columns when constructing each tree.\n",
    "\n",
    "\n",
    "### üí° Parameters tuning\n",
    "\n",
    "   *  We are utilizing the **RandomSearchCV** provided by scikit-learn to tune our parameters.\n",
    "\n",
    "\n",
    " ##### üëâ    Why we chose this framework ?\n",
    "\n",
    "  * RandomSearchCV is useful when we have **many parameters** to try and the training time is very long. The **training time** for XGBoost is relatively long compared to non-tree-based models. Considering that cross-validation takes a longer time as well, the train load is even heavier.\n",
    "  * The **number of parameters** to consider for XGBoost trees is particularly high and the magnitudes of influence are imbalanced. Compared to GridSearch, RandomSearch is more suitable in this situation.\n",
    "\n",
    "\n",
    "### üí° Results\n",
    "\n",
    "##### üëâ    F1 score of Model on public dataset (20%)\n",
    "* **0.6607**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Model Implementation\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read the data\n",
    "print(\"reading CSVs...\")\n",
    "train_df = pd.read_csv(\"train_tfidf_features.csv\")\n",
    "test_df = pd.read_csv(\"test_tfidf_features.csv\")\n",
    "\n",
    "print(\"creating training X and y...\")\n",
    "X = train_df.drop(['id','label'], axis = 1).values\n",
    "Y = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "folds = 5\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "# xgb classifier\n",
    "xgb = XGBClassifier(objective='binary:logistic', silent=True, nthread=1, eta=0.2)\n",
    "\n",
    "# searching parameters\n",
    "params = {\n",
    "    'subsample': np.linspace(0.6, 1, 3),\n",
    "    'n_estimators': np.linspace(200, 600, 4, dtype=int),\n",
    "    'min_child_weight': [1, 2, 5],\n",
    "    'gamma': np.linspace(1, 3, 10),\n",
    "    'colsample_bytree': np.linspace(0.6, 0.8, 3)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# random search\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=30, scoring='f1', cv=skf.split(X,Y), verbose=1, random_state=1001)\n",
    "random_search.fit(X, Y)\n",
    "\n",
    "# best parameter\n",
    "# {'subsample': 0.7333333333333333,\n",
    "#  'n_estimators': 600,\n",
    "#  'min_child_weight': 2,\n",
    "#  'gamma': 2.7777777777777777,\n",
    "#  'colsample_bytree': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# retrain the model with a smaller eta\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, random_state=3, n_repeats=1)\n",
    "xgb_final_model = XGBClassifier(eta=0.01, objective='binary:logistic', silent=True, nthread=1, use_label_encoder=False, subsample=0.73, n_estimator=600, min_child_weight=2, max_depth=200, gamma=2.7, colssample_bytree=0.6)\n",
    "\n",
    "score_rf1 = cross_val_score(xgb_final_model, X, Y, scoring='f1_macro', cv=cv, n_jobs=2, verbose=3, error_score=\"raise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° ExtraTreesClassifier\n",
    "\n",
    "\n",
    " ##### üëâ    What is the model ? \n",
    "\n",
    "  * **ExtraTreesClassifier** is an ensemble machine learning model that is derived from deciesion trees. Also known as \"Extremely Randomized Trees\", ExtraTreesClassifier builds multiple trees and fits a number of randomized decision trees on various sub-samples of the dataset, averaging them to improve predictive accuracy and control over-fitting.\n",
    "\n",
    "           \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    " ##### üëâ    Why we chose to test this model ? \n",
    "  \n",
    " * Random Forest is generally quite capable of capturing the complex non-linear relationships of certain datasets while maintaining variance at a moderate level. However, due to the large number of features in this hate speech dataset, there is a much greater risk of over-fitting. Extra Trees's increase randomness compared to Random Forest allows it to have substantially lower variance which is well suited to the high dimensionality of our dataset.\n",
    "\n",
    "### üí° Hyperparameters of the model \n",
    "* **n_estimators:** int, default = 100\n",
    "<br> The number of trees in the forest.\n",
    "\n",
    "* **criterion:** {‚Äúgini‚Äù, ‚Äúentropy‚Äù, ‚Äúlog_loss‚Äù}, default = \"gini\"\n",
    "<br> The function to measure the quality of a split. \n",
    "\n",
    "* **max_depth:** int, default = None <br> The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "* **min_samples_split:** int or float, default = 2 <br> The minimum number of samples required to split an internal node. If int, then consider min_samples_split as the minimum number. If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.\n",
    "\n",
    "* **min_samples_leaf:** int or float, default = 1 <br> The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. \n",
    "  \n",
    "* **min_weight_fraction_leaf:** float, default = 0.0 <br> The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
    "\n",
    "* **max_features:** {‚Äúsqrt‚Äù, ‚Äúlog2‚Äù, None}, int or float, default = ‚Äùsqrt‚Äù <br> e number of features to consider when looking for the best split.If int, then consider max_features features at each split.\n",
    "\n",
    "If float, then max_features is a fraction and round(max_features * n_features) features are considered at each split. If ‚Äúauto‚Äù, then max_features=sqrt(n_features). If ‚Äúsqrt‚Äù, then max_features=sqrt(n_features). If ‚Äúlog2‚Äù, then max_features=log2(n_features). If None, then max_features=n_features.\n",
    "\n",
    "* **max_leaf_nodes:** int, default = None <br> Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
    "\n",
    "* **min_impurity_decrease:** float, default = 0.0 <br> A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "\n",
    "* **bootstrap:** bool, default=False <br> Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "\n",
    "* **random_state:** int, RandomState instance or None, default=None <br> Seed to control sources of randomness\n",
    "\n",
    "* **class_weight:** {‚Äúbalanced‚Äù, ‚Äúbalanced_subsample‚Äù}, dict or list of dicts, default=None <br> Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one. \n",
    "\n",
    "* **ccp_alpha:** non-negative float, default=0.0 <br> Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. \n",
    "\n",
    "* **max_samples:** int or float, default=None <br> If bootstrap is True, the number of samples to draw from X to train each base estimator.\n",
    "\n",
    "### üí° Hyperparameters tuning \n",
    "\n",
    "   *  We are utilizing the **Optuna** hyperparameter optimization framework to tune our hyperparameters.\n",
    "\n",
    "   \n",
    " ##### üëâ    Why we chose this framework ?\n",
    "\n",
    "  *  Optuna boasts the following features: \n",
    "      - **Lightweight, versatile, and platform agnostic architecture**\n",
    "           - Handle a wide variety of tasks with a simple installation that has few requirements.\n",
    "       - **Pythonic search spaces**\n",
    "            - Define search spaces using familiar Python syntax including conditionals and loops.\n",
    "       - **Efficient optimization algorithms**\n",
    "            - Adopt state-of-the-art algorithms for sampling hyperparameters and efficiently pruning unpromising trials.\n",
    "       - **Easy parallelization**\n",
    "            - Scale studies to tens or hundreds or workers with little or no changes to the code.\n",
    "       - **Quick visualization**\n",
    "            - Inspect optimization histories from a variety of plotting functions.\n",
    "     \n",
    "     Optuna also allowed us to find the optimal parameters at a faster rate as opposed to grid search though there is a trade off in accuracy. \n",
    "\n",
    "\n",
    "\n",
    "### üí° Results \n",
    "\n",
    "##### üëâ    F1 score of Model on public dataset (20%) \n",
    "\n",
    "* **0.72273**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Implementation\n",
    "\n",
    "# Imports\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"reading CSVs\")\n",
    "train_df = pd.read_csv(\"train_tfidf_features.csv\")\n",
    "test_df = pd.read_csv(\"test_tfidf_features.csv\")\n",
    "\n",
    "print(\"creating X and y\")\n",
    "X = train_df.drop(['id', 'label'], axis=1).values\n",
    "y = train_df['label'].values\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Hyperparameters tuning \n",
    "- The following trial was ran on a kaggle notebook for 12 hours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "    ### define params grid to search maximum accuracy\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 250)\n",
    "    max_depth = trial.suggest_int('max_depth', 500, 1100)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    class_weight = trial.suggest_categorical(\n",
    "        'class_weight', ['balanced', 'balanced_subsample'])\n",
    "    ccp_alpha = trial.suggest_loguniform('ccp_alpha', 1e-5, 1e-1)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 256)\n",
    "    min_weight_fraction_leaf = trial.suggest_loguniform(\n",
    "        'min_weight_fraction_leaf', 1e-6, 1e-2)\n",
    "    min_impurity_decrease = trial.suggest_float(\n",
    "        \"min_impurity_decrease\", 0, 0.1)\n",
    "    max_features = trial.suggest_loguniform('max_features', 1e-3, 1)\n",
    "    max_samples = trial.suggest_float(\"max_samples\", 0.5, 0.9)\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "    ### modeling with suggested params\n",
    "    model = ExtraTreesClassifier(n_estimators=n_estimators,\n",
    "                                 max_depth=max_depth,\n",
    "                                 class_weight=class_weight,\n",
    "                                 ccp_alpha=ccp_alpha,\n",
    "                                 min_samples_split=min_samples_split,\n",
    "                                 min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                 min_impurity_decrease=min_impurity_decrease,\n",
    "                                 max_features=max_features,\n",
    "                                 max_samples=max_samples,\n",
    "                                 criterion=criterion,\n",
    "                                 bootstrap=bootstrap,\n",
    "                                 n_jobs=2,\n",
    "                                 random_state=1)  # do not tune the seed\n",
    "\n",
    "    ## cross validation score\n",
    "    score = cross_val_score(model, X, y, n_jobs=2, cv=cv, scoring=\"f1_macro\")\n",
    "    f1_mean = score.mean()\n",
    "\n",
    "    return f1_mean\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')  # maximize accuracy\n",
    "study.optimize(objective, n_trials=None, timeout=42000, n_jobs=2,)\n",
    "\n",
    "print(study.best_trial.params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Result of Hyperparemeter tuning with Optuna: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated results: 0.71643547\n",
    "# Test results: 0.72273\n",
    "model = ExtraTreesClassifier(n_estimators=144,\n",
    "                            max_depth=589,\n",
    "                            criterion=\"entropy\",\n",
    "                            class_weight=\"balanced_subsample\",\n",
    "                            ccp_alpha=6.267622143679782e-05,\n",
    "                            min_samples_split=157,\n",
    "                            min_weight_fraction_leaf=4.8022857076483334e-05,\n",
    "                            min_impurity_decrease=1.5576259402879695e-05,\n",
    "                            max_features=0.00502175457189458,\n",
    "                            max_samples=0.8999810323985775,\n",
    "                            bootstrap=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation and Submission\n",
    "\n",
    "FILE_NAME = '/kaggle/working/etc2.csv'\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, random_state=3, n_repeats=3)\n",
    "\n",
    "score = cross_val_score(model, X, y, scoring='f1_macro',\n",
    "                        cv=cv, n_jobs=2, verbose=3, error_score=\"raise\")\n",
    "\n",
    "print(\"LATEST\")\n",
    "print(score)\n",
    "print(score.mean())\n",
    "# 0.7164\n",
    "print(score.std())\n",
    "#0.00810\n",
    "\n",
    "model.fit(X, y)\n",
    "idColDf = test_df[\"id\"]\n",
    "X_submit_test = test_df.drop(['id'], axis=1).values\n",
    "# Submission using OUR logistic regression weights\n",
    "y_submit_pred = model.predict(X_submit_test)\n",
    "y_submit_pred_df = pd.DataFrame(y_submit_pred)\n",
    "submission = pd.concat([idColDf, y_submit_pred_df], axis=1)\n",
    "submission.columns = ['id', 'label']\n",
    "submission.to_csv(FILE_NAME, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° AutoML + Hyper-parameter tuning with TPOT\n",
    "\n",
    "\n",
    " ##### üëâ    What is TPOT ? \n",
    "\n",
    "  * **TPOT** stands for Tree-based Pipeline Optimization Tool. It is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming\n",
    "\n",
    "           \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    " ##### üëâ    Why we chose to use TPOT ? \n",
    "  \n",
    " * TPOT automates the most tedious part of machine learning by intelligently exploring thousands of possible pipelines to find the best one the given data. \n",
    " * It is built on scikit-learn (familiar interface)\n",
    "\n",
    "### üí° Key parameters of TPOT \n",
    "* **generations:** int or None, optional. default = 100\n",
    "<br> Number of iterations to the run pipeline optimization process.\n",
    "\n",
    "* **population_size:** nt, optional (default=100)\n",
    "<br> Number of individuals to retain in the genetic programming population every generation. Must be a positive number.\n",
    "\n",
    "* **scoring:** string or callable, optional (default='accuracy') <br> Function used to evaluate the quality of a given pipeline for the classification problem. The following built-in scoring functions can be used:\n",
    "\n",
    "* **cv:** int, cross-validation generator, or an iterable, optional (default=5) <br> Cross-validation strategy used when evaluating pipelines.\n",
    "\n",
    "* **config_dict:** Python dictionary, string, or None, optional (default=None) <br> A configuration dictionary for customizing the operators and parameters that TPOT searches in the optimization process.\n",
    "  \n",
    "\n",
    "* **random_state:** int, RandomState instance or None, default=None <br> he seed of the pseudo random number generator used in TPOT.\n",
    "\n",
    "\n",
    "### Imports: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "import time\n",
    "print(\"reading CSVs\")\n",
    "train_df = pd.read_csv(\"/kaggle/input/50007-dataset/train_tfidf_features.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/50007-dataset/test_tfidf_features.csv\")\n",
    "\n",
    "print(\"creating X and y\")\n",
    "X = train_df.drop(['id', 'label'], axis=1).values\n",
    "y = train_df['label'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPOT Search Space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchDict = {\n",
    "\n",
    "    # Classifiers\n",
    "    'sklearn.naive_bayes.BernoulliNB': {\n",
    "        'alpha': [1.882, 5, 0.1],\n",
    "        'fit_prior': [False]\n",
    "    },\n",
    "    \n",
    "    'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'criterion': [\"gini\"],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        \"max_depth\": range(1, 2002,100),\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "\n",
    "    'sklearn.tree.DecisionTreeClassifier': {\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_depth': range(1, 11),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'ccp_alpha':[0.0001,0.001,0.005,0.01,0.05]\n",
    "    },\n",
    "    \n",
    "    'sklearn.svm.LinearSVC': {\n",
    "        'penalty': [\"l1\", \"l2\"],\n",
    "        'loss': [\"hinge\", \"squared_hinge\"],\n",
    "        'dual': [True, False],\n",
    "        'tol': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "        'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.]\n",
    "    },\n",
    "\n",
    "\n",
    "    'sklearn.linear_model.SGDClassifier': {\n",
    "        'loss': ['log', 'hinge', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "        'penalty': ['elasticnet'],\n",
    "        'alpha': [3e-06, 0.01, 0.001],\n",
    "        'learning_rate': ['invscaling'],\n",
    "        'fit_intercept': [True, False],\n",
    "        'l1_ratio': [0.25, 0.0, 1.0, 0.75, 0.5],\n",
    "        'eta0': [0.1, 1.0, 0.01,0.0012],\n",
    "        'power_t': [0.5, 0.0, 1.0, 0.1, 100.0, 10.0, 50.0]\n",
    "    },\n",
    "\n",
    "    # Preprocesssors\n",
    "    'sklearn.preprocessing.Binarizer': {\n",
    "        'threshold': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.cluster.FeatureAgglomeration': {\n",
    "        'linkage': ['ward', 'complete', 'average'],\n",
    "        'affinity': ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.MaxAbsScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.MinMaxScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.Normalizer': {\n",
    "        'norm': ['l1', 'l2', 'max']\n",
    "    },\n",
    "\n",
    "    'sklearn.kernel_approximation.RBFSampler': {\n",
    "        'gamma': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.RobustScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.StandardScaler': {\n",
    "    },\n",
    "\n",
    "    'tpot.builtins.ZeroCount': {\n",
    "    },\n",
    "\n",
    "    # Selectors\n",
    "    'sklearn.feature_selection.SelectFwe': {\n",
    "        'alpha': np.arange(0, 0.05, 0.001),\n",
    "        'score_func': {\n",
    "            'sklearn.feature_selection.f_classif': None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.SelectPercentile': {\n",
    "        'percentile': range(1, 100),\n",
    "        'score_func': {\n",
    "            'sklearn.feature_selection.f_classif': None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.VarianceThreshold': {\n",
    "        'threshold': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code that is run on Kaggle (set to approximately 12 hours each run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=3)\n",
    "# define search\n",
    "print(\"Starting with highly custom light config dict\")\n",
    "start_time = time.time()\n",
    "periodic_checkpoint_folder = \"/kaggle/working/checkpoints/\"\n",
    "model = TPOTClassifier(generations=500, population_size=30, cv=cv, config_dict=searchDict,\n",
    "                       scoring='f1_macro', verbosity=3, random_state=random.randint(1, 999999999),\n",
    "                       n_jobs=2, periodic_checkpoint_folder=periodic_checkpoint_folder,\n",
    "                       max_time_mins=700, max_eval_time_mins=15)\n",
    "# perform the search\n",
    "model.fit(X, y)\n",
    "# export the best model\n",
    "model.export('tpot_best_model.py')\n",
    "end_time = time.time()\n",
    "\n",
    "# Results\n",
    "print('TPOT classifier finished in %s seconds' % (end_time - start_time))\n",
    "print('Best pipeline test score: %.3f' % model.score(X, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some of the best cross-validated **Results** from multiple runs of TPOT on Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Normalizer, FunctionTransformer, RobustScaler, MaxAbsScaler, Binarizer, MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectPercentile, f_classif\n",
    "from tpot.export_utils import set_param_recursive\n",
    "from tpot.builtins import StackingEstimator\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from copy import copy\n",
    "\n",
    "# Average CV score on the training set was: 0.7165325962375743\n",
    "cl0 = make_pipeline(\n",
    "    make_union(\n",
    "        FunctionTransformer(copy),\n",
    "        make_pipeline(\n",
    "            make_union(\n",
    "                Normalizer(norm=\"max\"),\n",
    "                SelectPercentile(score_func=f_classif, percentile=5)\n",
    "            ),\n",
    "            MaxAbsScaler()\n",
    "        )\n",
    "    ),\n",
    "    StackingEstimator(estimator=SGDClassifier(alpha=0.001, eta0=1.0, fit_intercept=False, l1_ratio=0.5,\n",
    "                                              learning_rate=\"invscaling\", loss=\"modified_huber\", penalty=\"elasticnet\", power_t=0.5)),\n",
    "    BernoulliNB(alpha=1.0, fit_prior=True)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(cl0.steps, 'random_state', 2)\n",
    "\n",
    "\n",
    "# Average CV score on the training set was: 0.7167734749214567\n",
    "cl2 = make_pipeline(\n",
    "    StackingEstimator(estimator=DecisionTreeClassifier(\n",
    "        criterion=\"gini\", max_depth=8, min_samples_leaf=9, min_samples_split=6)),\n",
    "    StackingEstimator(estimator=SGDClassifier(alpha=0.001, eta0=1.0, fit_intercept=False, l1_ratio=0.75,\n",
    "                                              learning_rate=\"invscaling\", loss=\"perceptron\", penalty=\"elasticnet\", power_t=0.1)),\n",
    "    BernoulliNB(alpha=1.0, fit_prior=False)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(cl2.steps, 'random_state', 222)\n",
    "\n",
    "\n",
    "# Average CV score on the training set was: 0.7192365888770997\n",
    "cl12 = make_pipeline(\n",
    "    SelectPercentile(score_func=f_classif, percentile=77),\n",
    "    SelectPercentile(score_func=f_classif, percentile=68),\n",
    "    StackingEstimator(estimator=SGDClassifier(alpha=0.001, eta0=0.0012, fit_intercept=False,\n",
    "                                              l1_ratio=0.0, learning_rate=\"invscaling\", loss=\"hinge\", penalty=\"elasticnet\", power_t=0.5)),\n",
    "    BernoulliNB(alpha=2.300000000000001, fit_prior=False)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(cl12.steps, 'random_state', 422)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° **Final Model**: VotingClassifier (Kaggle Link: https://www.kaggle.com/overspleen/submit/edit)\n",
    "\n",
    "\n",
    " ##### üëâ    What is the model ? \n",
    "\n",
    "  * **VotingClassifier** is a machine learning model that trains an ensemble of user-defined models and predicted an output based on the weights (voting power) assigned to each of the model.\n",
    "    \n",
    " ##### üëâ    Motivation for using VotingClassifier \n",
    "  \n",
    " * Assuming that classifier are independent, increasing the number of classifiers can increase the validation and test results, especially if the weights (voting power) for each classifiers are tuned. This is can be true even if some of the models do not have high validation score.\n",
    "\n",
    "### üí° Main Hyperparameters of the model \n",
    "* **estimators:** list of (str, estimator) tuples\n",
    "<br> nvoking the fit method on the VotingClassifier will fit clones of those original estimators\n",
    "\n",
    "* **voting:** ‚Äòhard‚Äô, ‚Äòsoft‚Äô}, default=‚Äôhard‚Äô\n",
    "<br> If ‚Äòhard‚Äô, uses predicted class labels for majority rule voting. Else if ‚Äòsoft‚Äô, predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers.\n",
    "\n",
    "* **weights:** array-like of shape (n_classifiers,), default=None<br> Sequence of weights (float or int) to weight the occurrences of predicted class labels (hard voting) or class probabilities before averaging (soft voting). Uses uniform weights if None.\n",
    "\n",
    "### üí° Hyperparameters tuning (Kaggle Link: https://www.kaggle.com/code/overspleen/xtra-voting/edit/run/102572783)\n",
    "\n",
    "   *  We utilised the **Optuna** hyperparameter optimization framework to tune the weights.\n",
    "   \n",
    "\n",
    "### Reading Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"reading CSVs\")\n",
    "train_df = pd.read_csv(\"train_tfidf_features.csv\")\n",
    "test_df = pd.read_csv(\"test_tfidf_features.csv\")\n",
    "print(\"creating X and y\")\n",
    "X = train_df.drop(['id', 'label'], axis=1).values\n",
    "y = train_df['label'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Chosen for Voting Classifier: ExtraTreesClassifier and a mix of dissimilar models/pipelines from TPOT\n",
    "\n",
    "The Reason for this approach is to ensure that ExtraTreesClassifier does not overfit too much to the public test set on kaggle. The TPOT models hence has a regularising effect on the overall model (we assess that the reduction in variance is worth the potential increase in bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle link: https://www.kaggle.com/overspleen/submit/edit\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier, ExtraTreesClassifier\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Normalizer, FunctionTransformer, RobustScaler, MaxAbsScaler, Binarizer, MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectPercentile, f_classif\n",
    "from tpot.export_utils import set_param_recursive\n",
    "from tpot.builtins import StackingEstimator\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from copy import copy\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "# Weights chosen after Optuna hyperparamter tuning and manual adjustments\n",
    "w1 = 1\n",
    "w2 = 2\n",
    "w3 = 3.5\n",
    "w4 = 10\n",
    "weights = [w1, w2, w3, w4]\n",
    "\n",
    "cl0 = make_pipeline(\n",
    "    make_union(\n",
    "        FunctionTransformer(copy),\n",
    "        make_pipeline(\n",
    "            make_union(\n",
    "                Normalizer(norm=\"max\"),\n",
    "                SelectPercentile(score_func=f_classif, percentile=5)\n",
    "            ),\n",
    "            MaxAbsScaler()\n",
    "        )\n",
    "    ),\n",
    "    StackingEstimator(estimator=SGDClassifier(alpha=0.001, eta0=1.0, fit_intercept=False, l1_ratio=0.5,\n",
    "                                              learning_rate=\"invscaling\", loss=\"modified_huber\", penalty=\"elasticnet\", power_t=0.5)),\n",
    "    BernoulliNB(alpha=1.0, fit_prior=True)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(cl0.steps, 'random_state', 2)\n",
    "\n",
    "# Average CV score on the training set was: 0.7167734749214567\n",
    "cl2 = make_pipeline(\n",
    "    StackingEstimator(estimator=DecisionTreeClassifier(\n",
    "        criterion=\"gini\", max_depth=8, min_samples_leaf=9, min_samples_split=6)),\n",
    "    StackingEstimator(estimator=SGDClassifier(alpha=0.001, eta0=1.0, fit_intercept=False, l1_ratio=0.75,\n",
    "                                              learning_rate=\"invscaling\", loss=\"perceptron\", penalty=\"elasticnet\", power_t=0.1)),\n",
    "    BernoulliNB(alpha=1.0, fit_prior=False)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(cl2.steps, 'random_state', 222)\n",
    "\n",
    "# Average CV score on the training set was: 0.7192365888770997\n",
    "cl12 = make_pipeline(\n",
    "    SelectPercentile(score_func=f_classif, percentile=77),\n",
    "    SelectPercentile(score_func=f_classif, percentile=68),\n",
    "    StackingEstimator(estimator=SGDClassifier(alpha=0.001, eta0=0.0012, fit_intercept=False,\n",
    "                                              l1_ratio=0.0, learning_rate=\"invscaling\", loss=\"hinge\", penalty=\"elasticnet\", power_t=0.5)),\n",
    "    BernoulliNB(alpha=2.300000000000001, fit_prior=False)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(cl12.steps, 'random_state', 422)\n",
    "\n",
    "etc = ExtraTreesClassifier(n_estimators=144,\n",
    "                           max_depth=589,\n",
    "                           criterion='entropy',\n",
    "                           class_weight='balanced_subsample',\n",
    "                           ccp_alpha=6.267622143679782e-05,\n",
    "                           min_samples_split=157,\n",
    "                           min_weight_fraction_leaf=4.8022857076483334e-05,\n",
    "                           min_impurity_decrease=1.5576259402879695e-05,\n",
    "                           max_features=0.00502175457189458,\n",
    "                           max_samples=0.8999810323985775,\n",
    "                           bootstrap=True)\n",
    "estimatorsLast = [(\"cl0\", cl0), (\"cl2\", cl2), (\"cl12\", cl12), (\"etc\", etc)]\n",
    "\n",
    "\n",
    "model = VotingClassifier(estimators=estimatorsLast,\n",
    "                         voting='soft',\n",
    "                         verbose=False,\n",
    "                         n_jobs=2, weights=weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross validation score\n",
    "cv2 = RepeatedStratifiedKFold(n_splits=5, random_state=3, n_repeats=3)\n",
    "score = cross_val_score(model, X, y, n_jobs=2, cv=cv2, scoring=\"f1_macro\")\n",
    "\n",
    "print(\"LATEST\")\n",
    "print(score)\n",
    "print(score.mean())\n",
    "print(score.std())\n",
    "\n",
    "# LATEST\n",
    "# [0.73517317 0.71984801 0.70466551 0.71652156 0.72720915 0.71664385\n",
    "#  0.71723571 0.71669589 0.72687481 0.72986298 0.72181864 0.7291815\n",
    "#  0.72164984 0.7171528  0.71593628]\n",
    "\n",
    "# 0.7210979799320694\n",
    "# 0.007306143600200346\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = '/kaggle/working/etcBasicCouncil7.csv'\n",
    "model.fit(X,y)\n",
    "idColDf = test_df[\"id\"]\n",
    "X_submit_test = test_df.drop(['id'], axis = 1).values\n",
    "# Submission using OUR logistic regression weights\n",
    "y_submit_pred = model.predict(X_submit_test)\n",
    "y_submit_pred_df = pd.DataFrame(y_submit_pred)\n",
    "submission = pd.concat([idColDf,y_submit_pred_df],axis=1)\n",
    "submission.columns = ['id','label']\n",
    "submission.to_csv(FILE_NAME, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results: 0.72046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with ExtraTreesClassifier and Conclusion:\n",
    "\n",
    "Despite ExtraTreesClassifier having a higher test result (**0.72273**) on the public leaderboard than the VotingClassifier (**0.72046**), we still decided to use the results from the VotingClassifier as its 5-repeats 3-fold stratified cross-validated f1-score is higher (at **0.72109**) than that of the ExtraTreesClassifier (at **0.7164**). This implies that the VotingClassifier may be more robust to unseen test examples compared to the ExtraTreesClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "80f22b69b9f8d68ace34ab34260f84f100690723be29e4bfe0f6c780c6b4105c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
